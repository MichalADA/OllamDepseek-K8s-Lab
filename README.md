# OllamDepseek-K8s-Lab
Ollama Deepseek OpenWebui Hosted on Kuberneters 



# Kubernetes Setup: Ollama + OpenWebUI + DeepSeek-R1

## Opis projektu

Ten projekt przedstawia wdroÅ¼enie Ollamy, OpenWebUI i modelu DeepSeek-R1 na klastrze Kubernetes. 

WdroÅ¼enie odbywa siÄ™ z wykorzystaniem narzÄ™dzi:
- Kubernetes
- Devbox
- Taskfile

CaÅ‚oÅ›Ä‡ umoÅ¼liwia uruchomienie interaktywnego interfejsu OpenWebUI oraz modelu DeepSeek-R1 w Ollamie.

---

## Architektura projektu

Projekt zawiera nastÄ™pujÄ…ce komponenty:

- **Ollama** â€“ backend AI
- **OpenWebUI** â€“ interaktywny interfejs
- **DeepSeek-R1** â€“ model jÄ™zykowy dziaÅ‚ajÄ…cy w Ollamie

Struktura katalogÃ³w:

```
.
â”œâ”€â”€ manifests
â”‚   â”œâ”€â”€ Ingress.yaml
â”‚   â”œâ”€â”€ Namespace.yaml
â”‚   â”œâ”€â”€ Ollama.yaml
â”‚   â”œâ”€â”€ OllamaService.yaml
â”‚   â”œâ”€â”€ OpenWebUI.yaml
â”‚   â”œâ”€â”€ Service.yaml
â”‚   â””â”€â”€ Volume.yaml
â”œâ”€â”€ scripts
â”œâ”€â”€ devbox.json
â”œâ”€â”€ devbox.lock
â”œâ”€â”€ README.md
â””â”€â”€ Taskfile.yaml
```

---

## Wymagania

- Kubernetes (np. Kind)
- Devbox
- Docker
- Task

---

## Instalacja krok po kroku

1. **Uruchom Devbox**  
   ```bash
   devbox shell
   ```

2. **StwÃ³rz namespace:**  
   ```bash
   task create-namespace
   ```

3. **WdrÃ³Å¼ komponenty:**  
   ```bash
   task deploy-all
   ```

4. **Pobierz model DeepSeek-R1:**  
   ```bash
   task fetch-model
   ```

5. **Przekieruj porty dla dostÄ™pu lokalnego:**  
   ```bash
   task port-forward
   ```

6. **OtwÃ³rz aplikacjÄ™ OpenWebUI:**  
   ```
   http://localhost:3000
   ```

---

## PrzykÅ‚adowe dziaÅ‚anie modelu DeepSeek-R1

### OdpowiedÅº modelu na pytanie historyczne:

![DeepSeek - OdpowiedÅº na pytanie](./Tian.png)

### PrzykÅ‚adowy kod wygenerowany przez model:

![DeepSeek - Kod Pythona](./Deepsek-Kod.png)

---

### Wyjasnienie ::
Jak widac aplikacja dziala kod generuje siÄ™ dosÄ‡ wolno gdyÅ¼ jest to najslabszy model 


## Taskfile.yaml â€“ szczegÃ³Å‚y konfiguracji

```yaml
version: "3"

tasks:
  create-namespace:
    desc: "Create namespace"
    cmds:
      - kubectl create namespace ai-stack || true

  deploy-volume:
    desc: "Deploy volume"
    cmds:
      - kubectl apply -f manifests/Volume.yaml -n ai-stack

  deploy-ollama:
    desc: "Deploy Ollama"
    cmds:
      - kubectl apply -f manifests/Ollama.yaml -n ai-stack

  deploy-openwebui:
    desc: "Deploy OpenWebUI"
    cmds:
      - kubectl apply -f manifests/OpenWebUI.yaml -n ai-stack

  deploy-service:
    desc: "Deploy Service"
    cmds:
      - kubectl apply -f manifests/Service.yaml -n ai-stack
  
  deploy-service-ollama:
    desc: "Deploy Service-ollama"
    cmds:
      - kubectl apply -f manifests/OllamaService.yaml -n ai-stack
  
  deploy-ingress:
    desc: "Deploy Ingress"
    cmds:
      - kubectl apply -f manifests/Ingress.yaml -n ai-stack

  fetch-model:
    desc: "Pobranie modelu DeepSeek dla Ollamy"
    cmds:
      - |
        echo "Czekam na start kontenera Ollama..."
        until kubectl get pod -n ai-stack -l app=ollama -o jsonpath="{.items[0].status.phase}" | grep -q "Running"; do
          sleep 5
          echo "Czekam dalej..."
        done
        echo "Kontener uruchomiony, pobieram model..."
        kubectl exec -n ai-stack $(kubectl get pod -n ai-stack -l app=ollama -o jsonpath="{.items[0].metadata.name}") -- bash -c "
          ollama run deepseek-r1:1.5b"
    silent: false

  port-forward:
    desc: "Port forwarding for OpenWebUI and Ollama"
    cmds:
      - kubectl port-forward -n ai-stack svc/openwebui 3000:80 &
      - kubectl port-forward -n ai-stack svc/ollama 11434:11434 &
    silent: false

  deploy-all:
    desc: "Deploy all components"
    cmds:
      - task: create-namespace
      - task: deploy-volume
      - task: deploy-ollama
      - task: deploy-openwebui
      - task: deploy-service
      - task: deploy-service-ollama
      - task: deploy-ingress
      - task: fetch-model

  clean:
    desc: "Clean up the environment"
    cmds:
      - kubectl delete namespace ai-stack
```

---

## Uwagi

- Upewnij siÄ™, Å¼e masz wystarczajÄ…ce zasoby pamiÄ™ci RAM i CPU, poniewaÅ¼ model DeepSeek-R1 moÅ¼e zuÅ¼ywaÄ‡ znacznÄ… iloÅ›Ä‡ zasobÃ³w.  
- W razie problemÃ³w z dostÄ™pem do OpenWebUI, zweryfikuj dziaÅ‚anie port-forwarding oraz logi kontenerÃ³w:

```bash
kubectl logs -n ai-stack -l app=openwebui
kubectl logs -n ai-stack -l app=ollama
```

---

**Projekt udokumentowany na potrzeby bloga symind.pl.**  
ðŸŽ¯ **Powodzenia!**
    
